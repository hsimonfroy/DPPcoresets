

\chapter{Improving concentration with DPP}
\label{chap__improv_conc_dpp}


\section{Quantitative results on variance}
\label{sec__quant_result_variance}
Based on the previous \cref{chap_correlated_sampling}, we are interested in quantifying the variance DPPs can yield, in order to leverage it into an improved sample complexity for coresets. We recall classical results on variance of Monte Carlo integration.

\subsection{Monte Carlo integration}
Denote $\mathcal{I}:= [-1,1]$ so that $\mathcal{I}^d$ is an hypercube of dimension $d$. Given some integrand $h \colon \mathcal{I}^d \to \RR$, we are interested in computing $\int_{\mathcal{I}^d} h(x) \dd \lambda(x)$, its integral on $\mathcal{I}^d$. The idea of Monte Carlo integration is to sample elements from $\mathcal{I}^d$ and to build an estimator $\estloss{}{\threequery}$ based on these elements.

We know from central limit theorem that as long as variance under sampling distribution exists, i.i.d. sampling Monte Carlo yields
\begin{equation}
	\Var{}{\estloss{}{\threequery}} \lesssim m^{-1}
\end{equation}
Moreover, we know from \cite{bakhvalov1959_approximate_calculation_integrals} that when the integrand $\threequery$ belongs to the Sobolev space $W^{s,2}(\mathcal{I})$, i.e. when its Fourier coefficients decay sufficiently rapidly,
\begin{equation}
	\label{eqn__lower_bound_variance_integration}
	\Var{}{\estloss{}{\threequery}} \gtrsim m^{-(1+\frac{2s}{d})}
\end{equation}
We refer to \cite{novak2014_complexity_numerical_integration} for a more recent inventory on complexity of numerical integration. 

Of course, there is plenty of room between this two variance rates. One would be tempted to get out of the i.i.d. framework, without assuming too much regularity of the integrand, and find an estimator that is as close as possible to the lower bound \cref{eqn__lower_bound_variance_integration}. We present next a recent result that falls into this description.



\subsection{Improved variance rate with DPPs}

Assume data $\mathcal{X}$ is strictly included in the hypercube $\mathcal{X} \subset \mathcal{I}^d$. For some integrand $h$, we are interested in constructing an estimator of the mean value of $h$ on $\mathcal{X}$.

\cite{bardenet2021sgddpp} show the existence of a sequence of DPP kernels $(\opekernel{m})_{m\in\NN}$, whose induced estimator has asymptotic variance $\OO( m ^{-(1+\frac 1 d)})$. We describe here the main key steps of the kernel construction, and introduce needed notations.

\paragraph{Kernel construction.}
Assume data $\mathcal{X}$ is generated by random samplings from a distribution $\gamma$ supported in the interior of the hypercube $\mathcal{I}^d$. Then, one can define its kernel density estimation (KDE)
\begin{equation*}
	\tilde \gamma(y) := \frac{1}{n\Delta^d} \sum_{x\in \mathcal{X}} k\left(\frac{x-y}{\Delta}\right)
\end{equation*}
where $\Delta >0$, and $k$ is a kernel unrelated to any DPP kernel, chosen so that $\int k \dd \lambda = 1$. 

Let now $\omega$ be a strictly positive probability density function on $\mathcal{I}$, and  denote by $q = q$ its tensor product density, supported on $\mathcal{I}^d$. Applying Gram-Schmidt algorithm in $L^2(q \dd \lambda)$ on multivariate monomials returns a sequence of orthonormal polynomial functions $(\phi_k)_{k\in \NN}$, the multivariate orthonormal polynomials with respect to density $q$. We refer to \cite{gautschi2004ope} for a review of orthogonal polynomials.

From there, define the multivariate Orthogonal Polynomial Ensemble (OPE) kernel associated to $q$
\begin{equation}
	K_q^{(m)}(x,y) := \sum_{k=1}^m \phi_k(x) \phi_k(y) \colon \mathcal{I}^d \times \mathcal{I}^d \to \RR
\end{equation}
which is the outer product of the $m$ first multivariate orthonormal polynomials. Because of orthonormality property, OPE kernel are projective kernels, and so it induces a projective DPP.

Noticeably, we obtained an OPE kernel associated to $q$, that we can correct to obtain an OPE kernel associated to the KDE distribution $\tilde \gamma$, by defining 
\begin{equation}
	K_{q, \tilde{\gamma}}^{(m)}(x, y):=\sqrt{\frac{q(x)}{\tilde{\gamma}(x)}} K_q^{(m)}(x, y) \sqrt{\frac{q(y)}{\tilde{\gamma}(y)}}.
\end{equation}
However, this projective DPP kernel is still defined on $\mathcal{I}^d \times \mathcal{I}^d$ but we are interested in sampling elements from $\mathcal{X}$, not $\mathcal{I}^d$. A last operation we not detail allows to restrict this kernel into $\opekernel{m}$, a projective DPP kernel defined on $\mathcal{X} \times \mathcal{X}$, or equivalently, a matrix of size $n \times n$ indexed by the elements of $\mathcal{X}$.

\paragraph{Improved variance rate.}
It turns out an estimator based on $\opekernel{m}$ yields improved variance. In particular, Proposition 4. and Equation (S14) from \cite{bardenet2021sgddpp} state that

\begin{tcolorbox}
	\begin{theorem}[\cite{bardenet2021sgddpp}]
		\label{thm_sgdpaper}
		Let $m\in \NN$ and $\mathcal{S} \sim  \mathcal{DPP}(\opekernel{m})$. Define for all $h \in \RR^{\mathcal{X}}$ the correlated importance sampling estimator
		\begin{equation}
			\estloss{\mathcal{S}}{\threequery} := \sum_{x \in \mathcal{S}} \frac{\threequery(x)}{\opekernel{m}(x,x)}.
		\end{equation}
		If  $\lipschitz_\threequery := \operatorname{Lip}\left\{\frac{m\threequery}{K^{(m)}_{q, \tilde \gamma}} \right\}$ i.e. the Lipschitz constant of $x \mapsto \frac{m\threequery(x)}{K^{(m)}_{q, \tilde \gamma}(x,x)}$ is defined, then 
		\begin{equation}
			\label{eqn__improved_var}
			\Var{}{\estloss{\mathcal{S}}{\threequery}} = \lipschitz^2_\threequery \OO( m ^{-(1+\frac 1 d)}) +\OO( n^{-1/2}).
		\end{equation}
	\end{theorem}
\end{tcolorbox}

It is worth to say this variance generalize to the continuous case. Actually, pre-existing results from \cite{bardenet2020mcdpp} treated this case, with same variance improvement. Since the same continuous arguments are invoked in both continuous and discrete case, it explains why the construction of $\opekernel{m}$ relies first on constructing continuous DPP kernels, though it is not known if that detour can be shortcut in the discrete case.

Also, note that the higher $d$ is, the less the variance gain in \cref{eqn__improved_var}. Intuitively, this is because as the dimension increase, all points become already repelled from each others, so the addition of repulsiveness is less and less effective, or put differently, there is less and less redundancy in an independent sampling that we can get rid of by a negatively correlated sampling.

\note{}{cf. independent sphere packing in high dimension?}

We now introduce some notations
\begin{itemize}
	\item We denote by $\empdistr{\mathcal{S}}{}:=\frac{1}{|\mathcal{S}|} \sum_{x \in \mathcal{S}} \delta_x$ the empirical measure based on sample $\mathcal{S}  \subseteq \mathcal{X}$. 
	\item Hence for all function $\threequery$, we denote by $\empdistr{\mathcal{S}}{\threequery}:=\int_{\mathcal{X}} \threequery(x) d\empdistr{\mathcal{S}}{x} = \frac{1}{|\mathcal{S}|} \sum_{x \in \mathcal{S}} \threequery(x)$ the expectation of $\threequery$ with respect to $\empdistr{\mathcal{S}}{}$. Furthermore, given a distribution $\PP{}{}$ on $\mathcal{S}$, we denote by $\meanempdistr{\threequery}:=\EE{}{\empdistr{\mathcal{S}}{\threequery}}$, its expectation with respect to $\PP{}{}$. 
	\item Finally, the induced $L^1(\empdistr{\mathcal{S}}{})$ distance between two functions $\threequery$ and $\threequery'$ is denoted by $\dlone{\empdistr{\mathcal{S}}{}}{\threequery}{\threequery'}:=\empdistr{\mathcal{S}}{|\threequery - \threequery'|}$.
\end{itemize}  


so that we can reformulate the result from \cref{thm_sgdpaper} into the following corollary.
\begin{tcolorbox}
	\begin{corollary}
		\label{cor_sgdpaper}
		Let $m\in \NN$ and $\mathcal{S} \sim  \mathcal{DPP}(\opekernel{m})$.
		For all function $\twoquery \in \RR^{\mathcal{X}}$, we have
		\begin{equation*}
			\Var{}{\empdistr{\mathcal{S}}{\twoquery}} = \lipschitz^2_\twoquery \OO( m ^{-(1+\frac 1 d)}) +\OO( n^{-1/2})
		\end{equation*}
		where $\lipschitz_\twoquery := \operatorname{Lip}\left\{\frac{\opekernel{m}}{K^{(m)}_{q, \tilde \gamma}} \twoquery \right\}$ is the Lipschitz constant of $x \mapsto\frac{\opekernel{m}(x,x)}{K^{(m)}_{q, \tilde \gamma}(x,x)} \twoquery(x) $.
	\end{corollary}
\end{tcolorbox}

\begin{proof}
	We simply apply \cref{thm_sgdpaper} with $\threequery = \frac{\opekernel{m}g}{m}$, such that
	\begin{align*}
		\Var{}{\empdistr{\mathcal{S}}{\twoquery}} = \Var{}{\estloss{\mathcal{S}}{\threequery}} = \lipschitz^2_\threequery \OO( m ^{-(1+\frac 1 d)}) +\OO( n^{-1/2}),
	\end{align*}
	where $\lipschitz_\threequery$ is the Lipschitz constant of $x \mapsto \frac{m\threequery(x)}{K^{(m)}_{q, \tilde \gamma}(x,x)} = \frac{\opekernel{m}(x,x)}{K^{(m)}_{q, \tilde \gamma}(x,x)} \twoquery(x) $.

\end{proof}





\section{Regularity assumptions}
In order to translate the improved variance rate from \cref{cor_sgdpaper} into a concentration inequality and then a sample complexity bound for coreset, several assumptions are made and are discussed.

Let $\qset \in \RR^{\mathcal{X}}$ be the function space on which we want the coreset property to hold. With the notations of \cref{chap_intro_coresets}, define the following function space 
		\begin{equation*}
		\twoqset_m := \frac{m\qset}{\opekernel{m}\loss{\qset}} = \left\{x \mapsto \frac{m\query(x)}{\opekernel{m}(x,x)\loss{\query}} \mid \query \in \qset\right\} \in \RR^{\mathcal{X}}.
	\end{equation*}
Note then that for any $\query \in \qset$, we can define $g := \frac{m\query}{\opekernel{m}\loss{\query}} \in \twoqset_m$ which verifies
	\begin{equation}
		\label{def_ftog}
		\frac{\estloss{\mathcal{S}}{\query}}{\loss{\query}} = \empdistr{\mathcal{S}}{g}
		\quad \text{ and }\quad 
		\meanempdistr{g} = \EE{}{\empdistr{\mathcal{S}}{g}} = \frac{\EE{}{\estloss{\mathcal{S}}{\query}}}{\loss{\query}} = 1.
	\end{equation}




In the following sections, we crucially assume the functions sets $\twoqset_m$ verify boundedness in Lipschitz constant, infinite norm, and pseudo-dimension.
Formally, we assume there exists positive reals $\lipschitz, \bound \in \RR_+$ and $\pdim \in \NN$, such that for all $m \in \NN$
\begin{enumerate}
	\item \label{assum__lip} $\forall \twoquery \in \twoqset_m,\ \operatorname{Lip}\left\{\frac{\opekernel{m}}{K^{(m)}_{q, \tilde \gamma}}\twoquery \right\} \leq \lipschitz $
	\item \label{assum__inf}$\forall \twoquery \in \twoqset_m,\ \|\twoquery\|_{\infty} \leq \bound $
	\item \label{assum__pseudodim}$\operatorname{pdim}\twoqset_m \leq \pdim$
\end{enumerate}

\subsection{Discussing the assumptions}
We invoke asymptotic phenomena to justify our precedent assumptions. With notations from previous \cref{sec__quant_result_variance}, we first have that for large $n$, the KDE estimation is close to the true density, namely $\tilde \gamma \xrightarrow[n \to +\infty]{} \gamma$. Second, next theorem describes the asymptotic behaviour of any OPE kernel, and in particular confirms that $K_q^{(m)}$ is of order $m$.
\begin{tcolorbox}
	\begin{theorem}[\cite{simon2010_totik_thm}]
		Assume $q$ is continuous. Then, for every $\epsilon>0$, we have uniformly for $x\in [-1+\epsilon,1-\epsilon]^d$
		\begin{equation}
			\frac{m}{K_q^{(m)}(x, x)} \xrightarrow[m \to +\infty]{} \frac{q(x)}{q_{\mathrm{eq}}(x)}
		\end{equation}
	\end{theorem}
	where $q_{\mathrm{eq}} = x \mapsto \prod_{k=1}^d \frac{1}{\pi \sqrt[]{1-x_k^2}}$.
\end{tcolorbox}

Finally, the restriction of $K^{(m)}_{q, \tilde \gamma}$ into $\opekernel{m}$ is such that for large $n$, we have $K^{(m)}_{q, \tilde \gamma} \simeq \opekernel{m}$. Put together, the asymptotic behaviour of the set $\twoqset_m$ is 
\begin{equation}
	\twoqset_m \to \twoqset := \frac{\qset\gamma}{\loss{\qset}q_{\mathrm{eq}}} = \left\{x \mapsto \frac{\query(x)\gamma(x)}{\loss{\query}q_{\mathrm{eq}}(x)} \mid \query \in \qset\right\} \in \RR^{\mathcal{X}}.
\end{equation}


 Then, assumptions we made on $\twoqset_m$ for every $m\in \NN$ translates to assumptions on $\twoqset$. Indeed, if $\twoqset$ verifies boundedness in Lipschitz constant, infinite norm, and pseudo-dimension, we have
\begin{enumerate}
	\item $\forall \twoquery \in \twoqset_m,\ \operatorname{Lip}\left\{\frac{\opekernel{m}}{K^{(m)}_{q, \tilde \gamma}}\twoquery \right\} \lesssim \sup_{\query \in \qset}\operatorname{Lip}\left\{\frac{\query\gamma}{\loss{\query}q_{\mathrm{eq}}} \right\} =: \lipschitz$
	\item $\forall \twoquery \in \twoqset_m,\ \|\twoquery\|_{\infty} \lesssim \|\frac{\query\gamma}{\loss{\query}q_{\mathrm{eq}}}\|_{\infty} \leq \|\frac{\gamma}{q_{\mathrm{eq}}}\|_{\infty} =:  \bound$
	\item $\operatorname{pdim}\twoqset_m \lesssim \operatorname{pdim}\twoqset =: \pdim$
\end{enumerate}

Note that $\twoqset$ plays a similar role as $\twoqset_s$ we introduced in \cref{eqn__g_sensitivity}. It is a function space whose properties influence the sample complexity bound, as we will now show.






\section{Concentration for fixed query}
\subsection{Chebyshov bound}

For any $\epsilon>0$ and $m\in \NN$, define the Chebyshov concentration bound
\begin{equation}
	\label{def_boundratecheb}
	\boundrate_{\textrm{Cheb}}(\epsilon, m) := \frac{1}{\epsilon^2} \sup_{\twoqset \in \{\twoqset_m \mid m \in \NN\}} \sup_{\twoquery \in \twoqset} \Var{}{\empdistr{\mathcal{S}}{\twoquery}}.
\end{equation}
Remark that from \cref{cor_sgdpaper} and the assumption \ref{assum__lip} on Lipschitz constant that $\boundrate_{\textrm{Cheb}}(\epsilon, m) = \frac {1} {\epsilon^2}\left(\lipschitz^2 \OO( m ^{-(1+\frac 1 d)}) +\OO( n^{-1/2})\right)$. From that, it follows


\begin{tcolorbox}
	\begin{theorem}[Chebyshov bound for fixed query]
		\label{thm_chebfixedtheta} 
		Let $m\in \NN$ and $\mathcal{S} \sim  \mathcal{DPP}(\opekernel{m})$. 

		Then for all $\epsilon >0$ and all $\query \in \qset$,
		\begin{equation*}
			\PP{}{\dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}} \leq \boundrate_{\textrm{Cheb}}(\epsilon, m)
		\end{equation*}
		
		
		Moreover, for all $\delta>0$ and for $n$ sufficiently large,
		\begin{equation*}
			m \gtrsim \left(\frac{\lipschitz^2}{\delta\epsilon^2} \right)^{\frac{1}{1+\frac 1 d}}
			\implies 
			\text{$\mathcal{S}$ is an $\epsilon$-coreset for $\query$ w.p. $1-\delta$}.
		\end{equation*}
	\end{theorem}
\end{tcolorbox}





\begin{proof}
	Let $\query \in \qset$, so that $g := \frac{m\query}{\opekernel{m}\loss{\query}} \in \twoqset_m$ verifies \cref{def_ftog}.

	Applying the Bienaym\'e-Chebyshov inequality, we obtain 
	\begin{align*}
		\PP{}{\dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}}
		&= \PP{}{\dnude{\nu}{\frac{\estloss{\mathcal{S}}{\query}}{\loss{\query}}}{1}>\epsilon}\\
		&= \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}}{\twoquery}}{\meanempdistr{\twoquery}}>\epsilon}\\ 
		&\leq \frac{1}{\varepsilon ^{2}}\Var{}{\empdistr{\mathcal{S}}{\twoquery}}\\
		&\leq \boundrate_{\textrm{Cheb}}(\epsilon, m)
		=\frac {1} {\epsilon^2}\left(\lipschitz^2 \OO( m ^{-(1+\frac 1 d)}) +\OO( n^{-1/2})\right)
	\end{align*}
	Hence, a sufficient condition for $\mathcal{S}$ to be an $\epsilon$-coreset for $\query$ w.p. $1-\delta$ is to have
	\begin{gather*}
		\boundrate_{\textrm{Cheb}}(\epsilon, m) \leq \delta 
		\iff
		m^{1+\frac 1 d} \gtrsim \frac{\lipschitz^2}{\delta \epsilon^2 + \OO(n^{-1/2})} = \frac {\lipschitz^2} {\delta\epsilon^2} \frac{1}{1 + \frac{1}{\delta \epsilon^2}\OO(n^{-1/2})}.
	\end{gather*} 
	For sufficiently large $n$ (potentially $n\gtrsim \delta^{-2} \epsilon^{-4}$), we can control the second factor and thus obtain the bound
	\begin{equation*}
		m \gtrsim \left(\frac{\lipschitz^2}{\delta\epsilon^2} \right)^{\frac{1}{1+\frac 1 d}}.
	\end{equation*}
\end{proof}

We obtained a sample complexity bound with improved dependency in $\epsilon$ compared to the one from \cref{thm_hoeffdingfixedquery} for the i.i.d. sampling framework. Our result is $\OO(\epsilon^{\frac{-2}{1+\frac{1}{d}}})$ whereas the latter is $\OO(\epsilon^{-2})$. As for the variance, the higher the dimension $d$ is, the less is the gain in sample complexity, because the less there is redundancy to get rid of by a negatively correlated sampling.

On the other hand, the dependency in $\delta$ is worsened compared to i.i.d. sampling. Our result is $\OO(\delta^{\frac{-2}{1+\frac{1}{d}}})$ whereas the latter is $\log \delta^{-1}$.
We propose to tackle this dependency, before generalizing the obtained bound to all queries.









\subsection{Breuer and Duits bound}
 
There actually exists a concentration bound for projective DPPs from \cite{breuer2013nevai}, that still can leverage the increased variance rate from \cite{bardenet2021sgddpp}, and that is tighter than Chebyshov bound.

\begin{tcolorbox}
	\begin{theorem}[\cite{breuer2013nevai}]
		\label{thm_breuer}
		Let $\epsilon>0$, any bounded function $\threequery$, any projective DPP kernel $K$, and let $\mathcal{S} \sim  \mathcal{DPP}(K)$.\\

		Then for any linear statistic $X_\threequery := \sum_{x\in\mathcal{S}}\threequery(x)$,
		\begin{equation*}
			\PP{}{\dnude{}{X_\threequery}{\EE{}{X_\threequery}} > \epsilon} \leq	
			\begin{cases}
				2 \exp \left(-\frac{\epsilon^2}{4 A \Var{}{X_\threequery}}\right) 
				& \text { if } \epsilon<\frac{2 A \Var{}{X_\threequery}}{3\|\threequery\|_{\infty}}\\
				2 \exp \left(-\frac{\epsilon}{6\|\threequery\|_{\infty}}\right) 
				& \text { otherwise }
			\end{cases}
		\end{equation*}	
		where $A \simeq 7819$ so does not depend on $\threequery$, $K$ or $\epsilon$.
	\end{theorem}
\end{tcolorbox}
Note that the second case in this concentration bound is tighter than the first. Indeed, 
\begin{equation*}
	\epsilon\geq\frac{2 A \Var{}{X_\threequery}}{3\|\threequery\|_{\infty}} \implies \frac{4 A \Var{}{X_\threequery}}{\epsilon^2} \leq \frac{3\|\threequery\|_{\infty}}{2 A \Var{}{X_\threequery}}\frac{4 A \Var{}{X_\threequery}}{\epsilon} = \frac{6\|\threequery\|_{\infty}}{\epsilon}
\end{equation*}
and thus we always have
\begin{equation}
	\label{eqn__remark_tighter}
	\PP{}{\dnude{}{X_\threequery}{\EE{}{X_\threequery}} > \epsilon} \leq	2 \exp \left(-\frac{\epsilon^2}{4 A \Var{}{X_\threequery}}\right).
\end{equation}	

Based on that remark, we define for any $\epsilon>0$ and $m\in \NN$
\begin{equation*}
	\boundrate_{\textrm{BD}}(\epsilon,m) := 2 \exp \left( \left(-
			4 A \boundrate_{\textrm{Cheb}}(\epsilon, m)
			\right)^{-1}
			\right)
\end{equation*}
which we call a Breuer and Duits (BD)-type bound, and that verifies what follows.





\begin{tcolorbox}
	\begin{theorem}[BD-type bound for fixed query]
		\label{thm_breuerfixedtheta}
		Let $m\in \NN$ and $\mathcal{S} \sim  \mathcal{DPP}(\opekernel{m})$. Then for all $\epsilon >0$ and all $\query \in \qset$,
		\begin{equation*}
			\PP{}{\dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}} \leq \boundrate_{\textrm{BD}}(\epsilon, m).
		\end{equation*}
		
		Moreover, for all $\delta>0$ and for $n$ sufficiently large,
		\begin{equation*}
			m \gtrsim \left(\frac{\lipschitz^2}{\epsilon^2}\log  \frac{2}{\delta } \right)^{\frac{1}{1+\frac 1 d}}
			\implies 
			\text{$\mathcal{S}$ is an $\epsilon$-coreset for $\query$ w.p. $1-\delta$}.
		\end{equation*}
	\end{theorem}
\end{tcolorbox}
\begin{proof}
	Let $\query \in \qset$, so that $g := \frac{m\query}{\opekernel{m}\loss{\query}} \in \twoqset_m$ verifies \cref{def_ftog}.

	Then we apply the Breuer and Duits bound from \cref{thm_breuer} taking $\threequery = \frac{\twoquery}{m}$.
	\begin{align*}
		\PP{}{\dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}}
		&= \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}}{\twoquery}}{\meanempdistr{\twoquery}}>\epsilon}\\ 
		&\leq 2 \exp \left(
		\begin{cases}
			\frac{-\epsilon^2}{4 A \Var{}{\empdistr{\mathcal{S}}{\twoquery}}}
			& \text { if } \epsilon< \frac{2 A m \Var{}{\empdistr{\mathcal{S}}{\twoquery}}}{3\|\twoquery \|_{\infty}}\\
			\frac{-\epsilon m}{6\|\twoquery\|_{\infty}} 
			& \text { otherwise }
		\end{cases}
		\right)\\
		&\leq 	2 \exp \left(-\frac{\epsilon^2}{4 A \Var{}{\empdistr{\mathcal{S}}{\twoquery}}}\right)\\
		&\leq 2 \exp \left( 
			\left(-4 A \boundrate_{\textrm{Cheb}}(\epsilon, m)\right)^{-1}
		\right)
		= \boundrate_{\textrm{BD}}(\epsilon,m)
	\end{align*}
	where we firstly used the remark in \cref{eqn__remark_tighter}, and secondly the definition \cref{def_boundratecheb} of $\boundrate_{\textrm{Cheb}}$.
	
	
	Hence, a sufficient condition for $\mathcal{S}$ to be an $\epsilon$-coreset for $\query$ w.p. $1-\delta$ is to have
	\begin{gather*}
		\boundrate_{\textrm{BD}}(\epsilon,m) \leq \delta
		\iff 
		\left(\log \frac{2}{\delta }\right)^{-1} \geq
		4 A \boundrate_{\textrm{Cheb}}(\epsilon, m)
	\end{gather*}
	and we know from \cref{thm_chebfixedtheta} this implies that for $n$ sufficiently large 
	\begin{equation*}
		m \gtrsim \left(\frac{\lipschitz^2}{\epsilon^2} \log  \frac{2}{\delta } \right)^{\frac{1}{1+\frac 1 d}}.
	\end{equation*}
\end{proof}

\paragraph{Discussing the tighter case.} Seeing \cref{thm_breuer}, one could wonder why we didn't leverage the second tighter case, noticed in \cref{eqn__remark_tighter}. Applied to our context, it would lead to the bound 
\begin{equation*}
	m \geq \frac{6\bound}{\epsilon} \log\frac{2}{\delta}
\end{equation*}
which is better than the one we shown. But for the second case to apply and obtain this bound, one would require

\begin{align*}
	\epsilon 
	\geq  \frac{2 A m \Var{}{\empdistr{\mathcal{S}}{\twoquery}}}{3\|\twoquery \|_{\infty}}
	= \OO\left(\frac{\lipschitz^2}{\|\twoquery \|_{\infty} m^{1/d}}\right)\\
	\iff
	m \gtrsim \left(\frac{\lipschitz^2}{\epsilon\|\twoquery \|_{\infty}}\right)^d
	\implies
	m \gtrsim \left(\frac{\lipschitz^2}{\epsilon\bound}\right)^d.
\end{align*}
Thereby, the condition on $\epsilon$ translates to a much worse bound on $m$, ruining the interest of the second case.
		 


\paragraph{Compared to the i.i.d. framework bound} from \cref{thm_hoeffdingfixedquery}, we obtained a better bound on coreset size for fixed query. This corroborate the qualitative results we obtained on variance comparison in \cref{sec__variance_arguments}, by quantifying the effect of increased variance rate on sampling complexity. 

Although the concentration bound from \cite{breuer2013nevai} pre-dates the works of \cite{tremblay2018dppcoreset}, it is only because of the improved variance rate from \cite{bardenet2021sgddpp} that it can yields improved concentration result. If one were to apply classical variance rate in $\OO(m^{-1})$ to it, it would find no improvements of the i.i.d. framework.



\section{Extension to all queries}
\label{sec_extension_all_queries}
In order to obtain an $\epsilon$-coreset for $\qset$, property \cref{eqn_querycoresetprop} must hold simultaneously for all queries $\query \in \qset$.









\begin{tcolorbox}
	\begin{theorem}[Infinite union bound]
		\label{thm_infinite_union_bound}
		Let $\threeqset \subseteq [0,\bound]^{\mathcal{X}}$ be a set of bounded functions defined on a base set $\mathcal{X}$, with $d'_{\threeqset} := \operatorname{pdim}\threeqset$ its pseudo-dimension (see \cref{def__pseudodim}). Let moreover $m\in \NN$ and $\PP{}{}$ a distribution supported on $\mathcal{X}^{m}$.\\

		Assume there exists a bounding function $\boundrate$ such that for all $\epsilon >0$, function $\threequery \in \threeqset$, integer $m \in \NN$, and let $\mathcal{S} \sim \PP{}{}$, we have the bound
		\begin{equation}
			\PP{}{\dnude{\nu}{\empdistr{\mathcal{S}}{\threequery}}{\meanempdistr{\threequery}} > \epsilon} \leq \boundrate(\epsilon, m)
		\end{equation}

		Then for all $\epsilon >0$ and all $m \in \NN$ such that $\boundrate(\epsilon/2, m) \leq 1/2$, it holds
		\begin{equation}
			\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}}{\threequery}}{\meanempdistr{\threequery}} > \epsilon} \leq 
			8\left(\frac{8e\bound}{\epsilon}\right)^{2d'_{\threeqset}} \boundrate(\epsilon/16, m)
		\end{equation}
	\end{theorem}
\end{tcolorbox}


We delay the proof of \cref{thm_infinite_union_bound} in the next \cref{sec__proof_thm_infinite_union_bound}

\begin{tcolorbox}
	\begin{theorem}[BD-type bound for all queries]
		\label{thm_breuerallqueries}
		Let $m\in \NN$ and $\mathcal{S} \sim  \mathcal{DPP}(\opekernel{m})$. 

		Then for all $\epsilon \in ]0,\bound]$ and all $\query \in \qset$
		\begin{equation*}
			\PP{}{\exists \query \in \qset,\ \dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}} 
			\leq 
			8\left(\frac{8e\bound}{\epsilon}\right)^{2\pdim}   \boundrate_{\textrm{BD}}(\epsilon/16, m)
		\end{equation*}
		
		Moreover, for all $\delta >0$ and for $n$ sufficiently large
		\begin{equation*}
			m \gtrsim \left(\frac{\lipschitz^2}{\epsilon^2} \left( \pdim \log \frac{\bound}{\epsilon} + \log \frac{1}{\delta }  \right) \right)^{\frac{1}{1+\frac 1 d}} 
			\implies 
			\text{$\mathcal{S}$ is an $\epsilon$-coreset for $\qset$ w.p. $1-\delta$}
		\end{equation*}
	\end{theorem}
\end{tcolorbox}


\begin{proof}
	Let $\query \in \qset$, so that $g := \frac{m\query}{\opekernel{m}\loss{\query}} \in \twoqset_m$ verifies \cref{def_ftog}.

	We know from \cref{thm_breuerfixedtheta} that for all $\epsilon \in ]0,\bound]$ and $m \in \NN$ we have
	\begin{equation*}
		\PP{}{\dnude{\nu}{\empdistr{\mathcal{S}}{\twoquery}}{\meanempdistr{\twoquery}} > \epsilon}  \leq \boundrate_{\textrm{BD}}(\epsilon, m)
	\end{equation*}
	
	Moreover, the assumption \ref{assum__inf} implies $\twoqset_m \in [0,M]^{\mathcal{X}}$. Hypotheses of \cref{thm_infinite_union_bound} are thus satisfied, and we can apply it taking $\threeqset=\twoqset_m$, which yields that for all $m \in \NN$ such that $\boundrate_{\textrm{BD}}(\epsilon/2, m) \leq 1/2$, it holds
	\begin{align*}
		\PP{}{\exists \query \in \qset,\ \dnude{\nu}{\estloss{\mathcal{S}}{\query}}{\loss{\query}}>\epsilon\loss{\query}} 
		= \PP{}{\exists \twoquery \in \twoqset_m,\ \dnude{\nu}{\empdistr{\mathcal{S}}{\twoquery}}{\meanempdistr{\twoquery}} >  \epsilon}\\
		\leq  8\left(\frac{8e\bound}{\epsilon}\right)^{2d'_{\twoqset_m}}  \boundrate_{\textrm{BD}}(\epsilon/16, m)
		\leq  8\left(\frac{8e\bound}{\epsilon}\right)^{2\pdim} \boundrate_{\textrm{BD}}(\epsilon/16, m)
	\end{align*}
	where we used the assumption \ref{assum__pseudodim} that for all $m \in \NN$, $\operatorname{pdim}\twoqset_m \leq \pdim$.
	
	Hence, a sufficient condition for $\mathcal{S}$ to be an $\epsilon$-coreset for $\qset$ w.p. $1-\delta$ is to have
	\begin{gather*}
		\boundrate_{\textrm{BD}}(\epsilon/16, m) \leq \frac{\delta}{8} \left(\frac{8e\bound}{\epsilon}\right)^{-2\pdim}
		\iff
		m \gtrsim \left(\frac{256\lipschitz^2}{\epsilon^2} \log \left( \frac{16}{\delta }\left(\frac{8e\bound}{\epsilon}\right)^{2\pdim}\right) \right)^{\frac{1}{1+\frac 1 d}}\\
		\iff m \gtrsim \left(\frac{\lipschitz^2}{\epsilon^2} \left(\log \frac{1}{\delta } + \pdim \log \frac{\bound}{\epsilon} \right)\right)^{\frac{1}{1+\frac 1 d}}
	\end{gather*}
	This rate is conditioned to the fact that $m$ is such that $\boundrate_{\textrm{BD}}(\epsilon/2, m) \leq 1/2$. But we know it holds as soon as $m \gtrsim \left(\frac{4\lipschitz^2}{\epsilon^2} \log 4 \right)^{\frac{1}{1+\frac 1 d}}$, which is trivially implied by the obtained bound.

\end{proof}





\section{Proof of \cref{thm_infinite_union_bound}}
\label{sec__proof_thm_infinite_union_bound}


We follow a similar proof scheme as in section 9.4 of \cite{haussler1992decisiontheoricgeneralizationofPACmodel}. We specifically revisit Lemma 12. and 13., getting rid of independency hypothesis, and making intermediary results more flexible to further improvements.


\begin{tcolorbox}
	\begin{lemma}[Symmetrisation]
		\label{lem_symm}
		Assume the hypothesis of \cref{thm_infinite_union_bound} about $\boundrate$.
		Let furthermore be $\epsilon>0$, $m\in \NN$, and $\mathcal{S}_1, \mathcal{S}_2 \overset{i.i.d.}{\sim} \PP{}{}$, two sequences of size $m$ independently sampled from the same distribution supported on $\mathcal{X}^m$.\\
		  
		Then for all $m \in \NN$ such that $\boundrate(\epsilon/2, m) \leq 1/2$
		\begin{equation*}
			\PP{}{ \exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon} 
			\leq 2\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/2 }
		\end{equation*}
	\end{lemma}
\end{tcolorbox}


\begin{proof}
	Let $\epsilon>0$ and take $m \in \NN$ such that $\boundrate(\epsilon/2, m) \leq 1/2$. Then let $\mathcal{S}_1$ be sampled such that $\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon$. This obviously happens with probability $\PP{}{\exists \threequery \in \threeqset, \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon }$.

	For such an $f$, we then independently sample $\mathcal{S}_2$ such that $\dnude{\nu}{\empdistr{\mathcal{S}_2}{\threequery}}{\meanempdistr{\threequery}} \leq \epsilon/2$. Because $\boundrate(\epsilon, m) \leq 1/2$, we know this happens with probability greater than $1-1/2 = 1/2$, and we thus have
	\begin{align*}
		&\PP{}{ \exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon}
		\frac 1 2 \\
		\leq\ &\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon \wedge \dnude{\nu}{\empdistr{\mathcal{S}_2}{\threequery}}{\meanempdistr{\threequery}} \leq \epsilon/2 } \\
		\leq\ &\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/2 }
	\end{align*}
	where we used the triangular inequality 
	\begin{equation*}
		\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} - \dnude{\nu}{\empdistr{\mathcal{S}_2}{\threequery}}{\meanempdistr{\threequery}} \leq   \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}}
	\end{equation*} 
\end{proof}







\begin{tcolorbox}
    \begin{definition}[Covering and Packing]
        Let $(\threeqset, d)$ be a metric space. 
        \begin{itemize}
            \item For any $\epsilon> 0$, a subset $\threeqset' \subseteq \threeqset$ is said to be $\epsilon$-separated if for all distinct $\threequery'_1, \threequery'_2 \in \threeqset'$, $d(\threequery'_1, \threequery'_2) > \epsilon$.
            \item The $\epsilon$-packing number on $(\threeqset, d)$, denoted by $\packing(\epsilon, \threeqset, d)$, is then defined as cardinality of the largest $\epsilon$-separated subset $\threeqset'$ of $\threeqset$.
        \end{itemize}
        Intuitively, the $\epsilon$-packing number is the maximal number of balls of radius $\epsilon/2$ that can fit into $\threeqset$ without intersecting.
        \begin{itemize}
            \item For any $\epsilon> 0$, a subset $\threeqset'$ of $\threeqset$ is said to be an $\epsilon$-cover of $\threeqset$ if for all $\threequery \in \threeqset$, there exists $\threequery' \in \threeqset'$ with $d(\threequery, \threequery') \leq \epsilon$.
            \item The $\epsilon$-covering number on $(\threeqset, d)$, denoted by $\covering(\epsilon, \threeqset, d)$, is then defined as cardinality of the smallest $\epsilon$-cover of $\threeqset$.
        \end{itemize}
        Intuitively, the $\epsilon$-covering number is the minimal number of balls of radius $\epsilon$ than can fill $\threeqset$, with possible overlaps.
    \end{definition}
\end{tcolorbox}

    One can easily check that for all $\epsilon>0$
    \begin{equation}
		\label{eqn__pack_cover_pack}
        \packing(2\epsilon, \threeqset, d) \leq \covering(\epsilon, \threeqset, d) \leq \packing(\epsilon, \threeqset, d)
    \end{equation}





\begin{tcolorbox}
    \begin{theorem}[\cite{pollard1984_convergence_stoch_proc} and \cite{haussler1995spherepacking}]
        \label{thm_pack}
        For any set $\mathcal{X}$, any probability distribution $\mu$ on $\mathcal{X}$, any
        set $\threeqset \subseteq [0,\bound]^{\mathcal{X}}$ of $\mu$-measurable positive functions on $\mathcal{X}$ bounded by some real $\bound$, and any $\epsilon\in]0,\bound]$, one has
        \begin{align*}
            \packing(\epsilon, \threeqset, \dlone{\mu}{}{}) 
			\leq \min \left\{
			2\left(\frac{2eM}{\epsilon}\log\frac{2e\bound}{\epsilon}\right)^{d'_{\threeqset}},\ 
			e(d'_{\threeqset}+1) \left(\frac{2e \bound}{\epsilon}\right)^{d'_{\threeqset}}\right\}
        \end{align*}
        where $d'_{\threeqset} =\operatorname{pdim}\threeqset$ is the pseudo-dimension of $\threeqset$.
    \end{theorem}
\end{tcolorbox}
Note that the second bound is better than the first one when $\epsilon$ is sufficiently small compared to $d'_{\threeqset}$ and vice versa.







\begin{tcolorbox}
	\begin{conjecture}
		\label{lem_infi_union_bound}
		Let $\epsilon >0$, $m\in \NN$, and  $\mathcal{S}_1, \mathcal{S}_2 \overset{i.i.d.}{\sim} \PP{}{}$, two sequences of size $m$ independently sampled from the same distribution supported on $\mathcal{X}^m$. Then
		
		\begin{gather*}
			\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon} \\\leq \\
			\sup_{\mathcal{S} \in \mathcal{X}^{2m} } \covering(\epsilon/4, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{}) \sup_{\threequery \in \threeqset} \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 }
		\end{gather*}
	\end{conjecture}
\end{tcolorbox}



\begin{proof}[Draft of Proof]
	Let $\mathcal{S}_1$ and $\mathcal{S}_2$ sampled such that $\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon$. 
	
	We denote their concatenation by $\mathcal{S} := \mathcal{S}_1 \uplus \mathcal{S}_2$ which is of size $2m$. Let then be taken $\threeqset'_{\mathcal{S}}$, a minimal $\epsilon/4$-cover of $\threeqset$ for the $\dlone{\empdistr{\mathcal{S}}{}}{}{}$ topology, then $|\threeqset'_{\mathcal{S}}| = \covering(\epsilon/4, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{})$. We thus know there exists $\threequery' \in \threeqset'_{\mathcal{S}}$ such that $\dlone{\empdistr{\mathcal{S}}{}}{\threequery}{\threequery'} \leq \epsilon/4$.


	Then triangular inequalities yields that
	\begin{align*}
		\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} &\leq \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery'}}{\empdistr{\mathcal{S}_2}{\threequery'}} + \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_1}{\threequery'}} + \dnude{\nu}{\empdistr{\mathcal{S}_2}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery'}}  \\
		&\leq \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery'}}{\empdistr{\mathcal{S}_2}{\threequery'}}  + \empdistr{\mathcal{S}_1}{\lvert \threequery-\threequery'\rvert} + \empdistr{\mathcal{S}_2}{\lvert\threequery-\threequery'\rvert}\\
		&\leq \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery'}}{\empdistr{\mathcal{S}_2}{\threequery'}} + 2 \dlone{\empdistr{\mathcal{S}}{}}{\threequery}{\threequery'}\\
		\iff \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery'}}{\empdistr{\mathcal{S}_2}{\threequery'}} &\geq \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} - 2  \dlone{\empdistr{\mathcal{S}}{}}{\threequery}{\threequery'} > \epsilon/2 
	\end{align*}
	Therefore
	\begin{equation*}
		\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon} \leq \PP{}{\exists \threequery \in \threeqset'_{\mathcal{S}},\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4}
	\end{equation*}
	By the law of total expectation, we obtain
	\begin{align*}
		\PP{}{\exists \threequery \in \threeqset'_{\mathcal{S}},\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4}
		&=\EE{}{ \1 \{\exists \threequery \in \threeqset'_{\mathcal{S}},\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 \} }\\
		&=\EE{}{ \PP{}{\exists \threequery \in \threeqset'_{\mathcal{S}},\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 \mid \threeqset'_{\mathcal{S}}}  }\\
		&=\EE{}{ \PP{}{\bigcup_{\threequery \in \threeqset'_{\mathcal{S}}} \{ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 \mid \threeqset'_{\mathcal{S}}\} }  }\\		
        &\overset{?}{\leq} \sup_{\threeqset'_{\mathcal{S}}} |\threeqset'_{\mathcal{S}}| \sup_{\threequery \in \threeqset} \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 }\\
		&= \sup_{\mathcal{S} \in \mathcal{X}^{2m} } N(\epsilon/4, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{} ) \sup_{\threequery \in \threeqset} \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/4 }
	\end{align*}
$\overset{?}{\leq}$ indicates this inequality is still to be proven. It consists of bounding the union probability of random event other a random set. Since we can bound uniformly both, event probability, and set cardinality, it could seem intuitive this random union bound hold. However, the conditioning by $\threeqset'_{\mathcal{S}}$ makes this bound non trivial and require further assumptions.

\end{proof}


From there, we are now able to prove \cref{thm_infinite_union_bound}. 
\begin{proof}
	Let $\epsilon>0$ and take $m \in \NN$ such that $\boundrate(\epsilon/2, m) \leq 1/2$. Combining \cref{lem_symm} and \cref{lem_infi_union_bound} gives
	\begin{align*}
		\PP{}{ \exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon} 
		&\leq 2\PP{}{\exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/2 }\\
		&\leq 2 \sup_{\mathcal{S} \in \mathcal{X}^{2m} } \covering(\epsilon/8, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{}) \sup_{\threequery \in \threeqset} \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/8 }
	\end{align*}

In order to bound the last term, first consider applying the union bound
	\begin{align*}
		\PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}} > \epsilon/8 } 
		&\leq \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} + \dnude{\nu}{\meanempdistr{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}}> \epsilon/8 }\\
		&\leq \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon/16 \vee  \dnude{\nu}{\meanempdistr{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}}> \epsilon/16 }\\
		&\leq \PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon/16 \vee  \dnude{\nu}{\meanempdistr{\threequery}}{\empdistr{\mathcal{S}_2}{\threequery}}> \epsilon/16 }\\
		&\leq 2\PP{}{\dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon/16 }\\
		&\leq 2 \boundrate(\threeqset, \epsilon/16, m)
	\end{align*}
Second, we know from \cref{eqn__pack_cover_pack} and \cref{thm_pack}
\begin{align*}
	\covering(\epsilon/8, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{})
	\leq \packing(\epsilon/8, \threeqset, \dlone{\empdistr{\mathcal{S}}{}}{}{})
	&\leq 2\left(\frac{16eM}{\epsilon}\log\frac{16e\bound}{\epsilon}\right)^{d'_{\threeqset}}
	&\leq  2\left(\frac{8e\bound}{\epsilon}\right)^{2d'_{\threeqset}}
\end{align*}
where we used the fact that $a \log a < (a/2)^2$ whenever $a \geq 5$, which is the case for $\frac{8eM}{\epsilon} \geq 5$ since $\epsilon \in ]0,\bound]$.

The two precedent bound does neither depend on $\mathcal{S}$ nor $f$, and therefore 
\begin{align*}
	\PP{}{ \exists \threequery \in \threeqset,\ \dnude{\nu}{\empdistr{\mathcal{S}_1}{\threequery}}{\meanempdistr{\threequery}} > \epsilon} 
	&\leq 8\left(\frac{8e\bound}{\epsilon}\right)^{2d'_{\threeqset}}\boundrate(\epsilon/16, m)\\
\end{align*}
which is the desired result.

\end{proof}













\begin{tcolorbox}[colback=red!10,title= Useless?]
	We define $\forall a,b \geq 0$ and $\forall \nu >0$
	\begin{equation}
		\dnu{\nu}{a}{b} := \frac{|a-b|}{a+b+\nu}
	\end{equation}
	
	From that definition, one can easily check
	\begin{proposition}
		\label{prop_dnu}
		For all $\nu>0$, the function $d_\nu$ verifies the following properties
		\begin{itemize}
			\item $d_\nu$ is a distance i.e. it verifies positivity, separation, symmetry and triangular inequality.
			\item $\forall a,b \geq 0,\ 0\leq \dnu{\nu}{a}{b} < \min( \frac{|a-b|}{a}, 1)$
			\item Moreover, if $\exists \bound\geq 0$ such that $a,b \le \bound$, then 
			\begin{equation*}
				\frac{|a-b|}{\nu + 2\bound} \le \dnu{\nu}{a}{b} \le \frac{|a-b|}{\nu}
			\end{equation*}
		\end{itemize}
	\end{proposition}


    
    Using properties \cref{prop_dnu} of $\dnude{\nu}{}{}$ distance yields that
    \begin{align*}
        \dnude{\nu}{\empdistr{\mathcal{S}_1}{\query}}{\empdistr{\mathcal{S}_1}{\query^*}} + \dnude{\nu}{\empdistr{\mathcal{S}_2}{\query}}{\empdistr{\mathcal{S}_2}{\query^*}}
        &\le \frac{\lvert \empdistr{\mathcal{S}_1}{\query-\query^*}\rvert}{\nu} + \frac{\lvert \empdistr{\mathcal{S}_2}{\query-\query^*}\rvert}{\nu} \\
        &\le \frac{2}{\nu}  \dlone{\empdistr{\mathcal{S}}{}}{\query}{\query^*}
    \end{align*}
\end{tcolorbox}








Note that we could also be interested in a biased cost function such as the diversified risk introduced by \cite{zhang2017dppminibatch}
$$
\tilde L{\query} =\frac{1}{m}\EE{x \sim \textrm{mDPP}}{\query(x)}=\frac{1}{m}\sum_{x_i \in \mathcal X} b_{i} \query\left(x_{i}\right)
$$
Then an unbiased estimator of $\tilde L$ is
\begin{equation*}
	\hat{\tilde L}_{\textrm{mDPP}}{\query} = \frac{1}{m}\sum_{x_i\in \mathcal S} \query(x_i)
\end{equation*}
We can switch between $L$ and $\tilde L$, substituting $\query(x_i)$ by $\frac{b_i \query(x_i)}{m}$.
\note{}{complete}




