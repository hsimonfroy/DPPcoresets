# Determinantal Point Processes for coreset sampling

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![arXiv:2411.00611](https://img.shields.io/badge/stat.ML-arXiv:2411.00611-b31b1b.svg)](https://arxiv.org/abs/2411.00611)

This repository contains the source code of the NeurIPS 2024 spotlight paper [**Small Coresets via Negative Dependence: DPPs, Linear Statistics, and Concentration**](https://neurips.cc/virtual/2024/poster/93945).

In short, Determinantal Point Processes (DPPs) can perform training set compression with strong guarantees, better than any i.i.d. sampling.
